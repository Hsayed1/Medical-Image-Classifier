# Medical-Image-Classifier

## Problem Statement
This project is pertaining to the medical industry and radiology scans done on patients. The problem of classifying radiology image scans using neural networks is very important. Firstly, it offers the potential to greatly enhance the efficiency of medical diagnosis. By automating the categorization of radiology images into their respective type, it streamlines the diagnostic process, allowing radiologists and medical professionals to dedicate more time to complex diagnostic tasks. Additionally, this automation leads to improved patient outcomes through early and accurate identification of imaging modalities, facilitating quicker medical interventions, which is particularly vital for time-sensitive conditions. Furthermore, the problem has broader implications for healthcare resource allocation. Resource optimization is possible as healthcare facilities can efficiently allocate experts and imaging equipment based on the type of scans, enhancing the overall efficiency of healthcare systems. In summary, the successful solution to this problem stands to greatly benefit healthcare by improving diagnostic efficiency, patient outcomes, resource allocation, telemedicine, education, and research in the medical field. The innovative aspect of my project is that I will be testing my CNN with different hyperparameters to discern the most optimal model for image classification. Along with that I plan to use a pre-tuned image classification model to try to come up with a more accurate model. The project's goal is to advance the field of medical imaging and healthcare by leveraging machine learning to address challenges. I hope to achieve a reliable and accurate automated classification system that has real-world applications in healthcare facilities and telemedicine services. By doing so, I aim to improve patient care, optimize resource allocation, and contribute to medical research and training. 

## Methodology
To perform this deep learning task, I used the “Medical Mnist” dataset provided by Kaggle. The dataset from Kaggle contains 58954 medical scan images. The features of this dataset is the image and the image type. In this particular dataset there are six possible types of images. They are abdomen CT scan, breast MRI, chest X-Ray, chest CT scan, hand X-Ray, and head CT scan. There are 10,000 images for each type of scan except for the breast MRI. Due to limitations by my computer, I was required to reduce the number of images in my dataset. I decided to randomly sample 5,000 images from each class so that there are a total of 30,000 images used. After that I was required to split my dataset into training, validation, and testing sets. I utilized the tf.keras.utils.image_dataset_from_directory method to do this. Within this method I was also resizing all of the images to 150x150 pixels and making each image 3 channels. I decided to keep the batch size at 32. I allocated 70% for training, 20% for validation, and 10% for testing.

## Implementation
In my implementation, I've created three machine learning models using TensorFlow and Keras in Python. The first model is a Convolutional Neural Network with convolutional and max-pooling layers, followed by fully connected layers for classification. Dropout layers are included to prevent overfitting. The second model is similar but incorporates Batch Normalization after each convolutional layer to improve stability during training. Both models are designed for image classification tasks, using the categorical cross entropy loss function. In the third model, I've used transfer learning by utilizing a pre-trained ResNet50 model from TensorFlow's Keras applications. The ResNet50 layers are frozen to retain their pre-trained weights, and I've added additional fully connected layers for task-specific classification. All implementations involve common preprocessing steps, such as rescaling pixel values to the [0, 1] range. I've used relu activation for convolutional and dense layers, and softmax for the output layer in multi-class classification. I used Adam as the optimizer for all of the models. These implementations use TensorFlow and Keras as the primary tools and frameworks for building and training the neural network models. 

## Final Thoughts
In analyzing the results of the experiments, it's evident that the models performed exceptionally well. The deep learning models exhibited effective learning patterns, achieving high accuracy levels and low losses. The experiments with pre-trained models showcased the power of leveraging existing knowledge for improved performance. However, it's important to acknowledge the limitations of these experiments. One notable limitation was the limitation placed by my environment I was running the experiments on. My computer is not that strong and Colab will not allow me to exceed a certain processing power. These together limit the complexity of models I could have along with the number of epochs I am able to run. Generally with higher epochs you can see the training and validation accuracies begin to converge which is most evident in experiment 7 and 8. In terms of potential areas for improvement, future work could focus on addressing the limitations by incorporating more diverse datasets, implementing data augmentation techniques, and exploring advanced model architectures. 

In summary, the experiments demonstrated the effectiveness of deep learning models, particularly those leveraging pre-trained architectures, in achieving high accuracy and robust performance for image classification tasks. The project achieves a milestone in machine learning for medical diagnosis, presenting a solution for automating the categorization of radiology images. The outcomes showcase enhanced diagnostic efficiency, quicker interventions for time-sensitive cases, and improved healthcare resource allocation. The application in telemedicine and its role in education and research further underscore the project's multifaceted contributions. For future work, refining models, expanding datasets to more classes, and addressing biases are essential to sustain the project's impact and relevance in the dynamic landscape of healthcare.
